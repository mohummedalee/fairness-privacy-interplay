{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70298fe-0b14-43b0-8b31-b7e370bcbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from datasets import Dataset\n",
    "\n",
    "from collections import Counter\n",
    "import evaluate\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f8dae48-d7ea-4ca3-9cb0-5bb9fd5d1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta_no_priv_84/').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26382609-8880-4da3-8747-6a5ca7832640",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c354969-563c-4ceb-a55e-00baeab49c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'happy': 1, 'sad': 0}\n",
    "\n",
    "# Download dataset from: https://github.com/mohummedalee/twitteraae-sentiment-data/\n",
    "def load_twitter_aae(dir):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    dialects = []\n",
    "    # for dial in ['aae', 'sae']:\n",
    "    for dial in ['aae']:\n",
    "        # for lab in ['happy', 'sad']:\n",
    "        for lab in ['happy']:\n",
    "            # load dialect x sentiment combination\n",
    "            fpath = os.path.join(dir, f'{dial}_{lab}')\n",
    "            fh = open(fpath, 'r', encoding='utf-8')\n",
    "            i = 0\n",
    "            while True:                \n",
    "                # print(i)\n",
    "                try:\n",
    "                    # pdb.set_trace()\n",
    "                    line = fh.readline()\n",
    "                    sentences.append(line.strip())\n",
    "                    labels.append(label_map[lab])\n",
    "                    dialects.append(dial.upper())\n",
    "                    i += 1 \n",
    "                except UnicodeDecodeError:\n",
    "                    print(f'could not read {fpath} at line {i}')\n",
    "                    continue\n",
    "                except EOFError:\n",
    "                    pdb.set_trace()\n",
    "                    fh.close()\n",
    "                    print(f'read {i} lines total from {fpath}')\n",
    "                    break\n",
    "\n",
    "    return sentences, labels, dialects\n",
    "\n",
    "DATA_DIR = 'fairness-privacy-local/twitteraae-sentiment-data/data/raw/sentiment_race'\n",
    "sentences, labels, dialects = load_twitter_aae(DATA_DIR)\n",
    "\n",
    "# dataset = Dataset.from_dict({\n",
    "#     'text': sentences,\n",
    "#     'label': labels,\n",
    "#     'dialect': dialects\n",
    "# }).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f35a426-8401-44d5-ba30-24059a44055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5750 6723\n"
     ]
    }
   ],
   "source": [
    "# how many pos/neg by dialect\n",
    "aae_inds = [i for i in range(len(dataset)) if dataset['dialect'][i] == 'AAE']\n",
    "sae_inds = [i for i in range(len(dataset)) if dataset['dialect'][i] == 'SAE']\n",
    "\n",
    "print(len(aae_inds), len(sae_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd82fffb-9f4c-47bc-9efa-109df25def34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAE: Counter({0: 5750})\n",
      "SAE: Counter({0: 3625, 1: 3098})\n"
     ]
    }
   ],
   "source": [
    "# compute label counts for both sae and aae\n",
    "print('AAE:', Counter(\n",
    "    [x.item() for x in dataset[aae_inds]['labels']]\n",
    "))\n",
    "print('SAE:', Counter(\n",
    "    [x.item() for x in dataset[sae_inds]['labels']]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745db956-b59d-4c9f-82ae-265e048ae00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e4f86716224a30a434e4b3f0bdf1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2030baadc84f3dab2887db0c4a6f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea60f2d3ec9d44b09aac84b70a486d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce04e550a36a4bd2b5ca34c98ab80275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3cbb9778ff4d1dbb0b29411cee23c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/12473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muh.ali/.conda/envs/fairness-privacy/lib/python3.11/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/muh.ali/.conda/envs/fairness-privacy/lib/python3.11/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize data\n",
    "MODEL_PATH = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "MAXLEN = 128\n",
    "\n",
    "def tokenize(instance):\n",
    "    tokenized = tokenizer(instance['text'], truncation=True, padding=\"max_length\", max_length=MAXLEN)\n",
    "    # return {**tokenized, \"label\": instance['label'], \"dialect\": instance['dialect']}\n",
    "    return {**tokenized}\n",
    "    \n",
    "dataset = dataset.map(tokenize, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d9a97f7-e3e6-4313-8dda-970e990d4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inds = np.loadtxt('fairness-privacy-local/val_inds.txt')\n",
    "val_inds = [int(v) for v in val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13db1ea2-a662-414d-a4f8-6435872b0ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SAE': 681, 'AAE': 566})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dataset[val_inds]['dialect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c499e-0948-407f-9e5e-cef581c15903",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7a6ef15-9a88-4fab-94b3-f0477e8f85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = sampler.SubsetRandomSampler(train_inds)\n",
    "dataset = dataset.rename_column('label', 'labels')\n",
    "val_sampler = sampler.SubsetRandomSampler(val_inds)\n",
    "# test_sampler = sampler.SubsetRandomSampler(test_inds)\n",
    "batch_size=64\n",
    "\n",
    "# train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61853441-8357-4cad-94e5-ad4d3661b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: should also know how cardiffnlp model does on SAE vs. AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70dabb10-162a-4949-b3b2-e563e9bc7f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a254f9dfbc1b432b870624d76142b131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8420208500400962}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # overall \n",
    "evaluate_accuracy_inds(model, val_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71f59d4f-cf5f-4157-b1f8-522788812400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disaggregated by dialect\n",
    "aae_inds_val = [i for i in val_inds if dataset['dialect'][i] == 'AAE']\n",
    "sae_inds_val = [i for i in val_inds if dataset['dialect'][i] == 'SAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "786158db-e607-4ea5-923d-f6d8cd79f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_inds(model, inds, batch_size=32):\n",
    "    inds_sampler = sampler.SubsetRandomSampler(inds)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, sampler=inds_sampler)\n",
    "\n",
    "    metric = evaluate.load('accuracy')\n",
    "    model.eval()  # switch to eval mode\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch_topass = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_topass)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "    \n",
    "    return metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa4f0a30-4455-4eb7-a516-2a7d83e48949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_for_sklearn(model, inds):\n",
    "    # output: y_true, y_pred\n",
    "    y_true, y_preds = [], []\n",
    "    for i in tqdm(inds):\n",
    "        y_true.append(dataset[i]['labels'].item())\n",
    "        pt = {\n",
    "            'input_ids': dataset[i:i+1]['input_ids'].to(device),\n",
    "            'attention_mask': dataset[i:i+1]['attention_mask'].to(device),\n",
    "            'labels': dataset[i:i+1]['labels'].to(device)\n",
    "        }\n",
    "        # pdb.set_trace()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**pt)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1)\n",
    "        y_preds.append(prediction.item())\n",
    "\n",
    "    return y_true, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2689559-9f7b-4ec2-80d0-3b830ea91861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dd10d6d6ed47a68546ce0f4be6e5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       566\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       566\n",
      "   macro avg       0.50      0.46      0.48       566\n",
      "weighted avg       1.00      0.92      0.96       566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muh.ali/.conda/envs/fairness-privacy/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/muh.ali/.conda/envs/fairness-privacy/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/muh.ali/.conda/envs/fairness-privacy/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "aae_true, aae_preds = evaluate_for_sklearn(model, aae_inds_val)\n",
    "print(classification_report(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4fa83f4-c3df-4e98-af6a-7351f8494bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[aae_inds_val]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "536b4e3c-94be-4d52-bd8e-d44e0bd6dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea01fa26ab074c8f992602a79d3cd706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9187279151943463}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy_inds(model, aae_inds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd694d12-2b28-487a-bf64-9ea0bdd8e2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7949672d4a35429a98e9078a5dd3f43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7782672540381792}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy_inds(model, sae_inds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49463af-13a4-44e4-bc52-9e253d812f98",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "addb32c8-b708-4fca-838d-75d2bdf381d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds = np.loadtxt('fairness-privacy-local/train_inds.txt')\n",
    "train_inds = [int(v) for v in train_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e06b06a-7704-4383-958c-3aa5c1458673",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_inds_train = [i for i in train_inds if dataset['dialect'][i] == 'AAE']\n",
    "sae_inds_train = [i for i in train_inds if dataset['dialect'][i] == 'SAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7bcfc6d-f790-43c2-96fa-264e821507be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [i.item() for i in dataset[aae_inds_train]['labels']]\n",
    "dataset[aae_inds_train]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0ef29-1345-42b5-a6dc-85b03555fb20",
   "metadata": {},
   "source": [
    "**NOTE**: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
