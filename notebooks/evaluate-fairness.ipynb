{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bcb18f6-f25f-4b00-b326-8ea1cabdce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir: /work/fairness-privacy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/work/fairness-privacy')\n",
    "print('working dir:', os.getcwd())\n",
    "\n",
    "import datasets\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac6035-e50d-4c4e-bdac-ccb2528f6fdd",
   "metadata": {},
   "source": [
    "### Load tokenizer and tokenize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477e6d75-2bc0-4213-8b5b-3451c6d880bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/fairness-privacy/condaenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_model = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "MAXLEN = 128\n",
    "\n",
    "def tokenize(batch, tokenizer, maxlen=MAXLEN):\n",
    "    tokenized = tokenizer(batch['text'], truncation=True, padding=\"max_length\", max_length=maxlen)    \n",
    "    return {**tokenized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64c51f7-9dca-4ea4-a36f-34ce6a0a3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /work/fairness-privacy/twitteraae-sentiment-data-split/test/cache-6ab371770c5f6a4f_*_of_00003.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/203475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/203475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_data = datasets.load_from_disk(\"/work/fairness-privacy/twitteraae-sentiment-data-split/\")\n",
    "test_sentiment_data_tok = sentiment_data['test'].map(tokenize, num_proc=3, batched=True, fn_kwargs={\"tokenizer\": tokenizer}).with_format(\"torch\")\n",
    "\n",
    "# separate out AAE and SAE points\n",
    "test_aae = test_sentiment_data_tok.filter(lambda pt: pt[\"dialect\"] == \"AAE\")\n",
    "test_sae = test_sentiment_data_tok.filter(lambda pt: pt[\"dialect\"] == \"SAE\")\n",
    "\n",
    "# build dataloaders\n",
    "aae_dataloader = DataLoader(test_aae, batch_size=64)\n",
    "sae_dataloader = DataLoader(test_sae, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910641e-3e39-4ce7-888c-fb68675909b9",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e52458-9bf8-4f03-b3ab-273d0ba6a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "nonpriv_model = AutoModelForSequenceClassification.from_pretrained(\"models-trained/roberta-no-priv-epochs_3-bs_128\").to(device)\n",
    "priv_model = AutoModelForSequenceClassification.from_pretrained(\"models-trained/roberta-priv-eps_8_epochs_3-bs_128\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffa6cd-cb22-4283-bd75-6b77373d1513",
   "metadata": {},
   "source": [
    "### Compute performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31f04f0d-c4f3-455d-9893-aebba767105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d86460-3fe4-4238-a061-2cdb68ec0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # switch to eval mode\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        batch_topass = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device)\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_topass)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        accuracy.add_batch(predictions=predictions, references=batch['label'])\n",
    "        f1.add_batch(predictions=predictions, references=batch['label'])\n",
    "    \n",
    "    return {'accuracy': accuracy.compute()['accuracy'], 'f1': f1.compute()['f1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "943e7ea0-0569-48b5-bcac-6ce89b79dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Non-private model ---\n",
      "Computing model performance...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e885ec1e3c9346da9521dd60a8737126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0a0d9245d8484e8cb8cc8f79a758a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Private model ---\n",
      "Computing model performance...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fe6bd00af847ff9a3fab0ae93cacea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324a0e5980654f558778d2a4bcd676cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('--- Non-private model ---')\n",
    "print('Computing model performance...')\n",
    "nonpriv_aae_perf = evaluate_model(nonpriv_model, aae_dataloader)\n",
    "nonpriv_sae_perf = evaluate_model(nonpriv_model, sae_dataloader)\n",
    "\n",
    "print('--- Private model ---')\n",
    "print('Computing model performance...')\n",
    "priv_aae_perf = evaluate_model(priv_model, aae_dataloader)\n",
    "priv_sae_perf = evaluate_model(priv_model, sae_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98f54413-cf0b-4084-a173-772d14bf2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model        Acc, SAE    Acc, AAE    F1, SAE    F1, AAE\n",
      "---------  ----------  ----------  ---------  ---------\n",
      "Non-priv.       0.858       0.735      0.898      0.802\n",
      "Priv.           0.691       0.61       0.817      0.758\n"
     ]
    }
   ],
   "source": [
    "table = [\n",
    "    [\"Model\",\"Acc, SAE\",\"Acc, AAE\", \"F1, SAE\", \"F1, AAE\"],    \n",
    "    [\"Non-priv.\", f\"{nonpriv_sae_perf['accuracy']:.3}\", f\"{nonpriv_aae_perf['accuracy']:.3}\", f\"{nonpriv_sae_perf['f1']:.3}\", f\"{nonpriv_aae_perf['f1']:.3}\"],\n",
    "    [\"Priv.\", f\"{priv_sae_perf['accuracy']:.3}\", f\"{priv_aae_perf['accuracy']:.3}\", f\"{priv_sae_perf['f1']:.3}\", f\"{priv_aae_perf['f1']:.3}\"]    \n",
    "]\n",
    "\n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
